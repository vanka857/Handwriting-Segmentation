{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kudrjavtseviv/DL-framework/.venv-hwr-train-2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "im1 = cv2.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import DiceLoss\n",
    "\n",
    "loss_fn = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#PyTorch\n",
    "ALPHA = 100\n",
    "GAMMA = 10\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #first compute binary cross-entropy \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        BCE_EXP = torch.exp(-BCE)\n",
    "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
    "                       \n",
    "        return focal_loss\n",
    "\n",
    "loss_fn = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#PyTorch\n",
    "ALPHA = 0.15\n",
    "BETA = 0.85\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(TverskyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = (inputs * targets).sum()    \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "       \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        \n",
    "        return 1 - Tversky\n",
    "    \n",
    "loss_fn = TverskyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7727),\n",
       " tensor(0.8718),\n",
       " tensor(0.4048),\n",
       " tensor(0.3750),\n",
       " tensor(0.5455),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(10, 10, 2, 2)\n",
    "a[4][4] = 1\n",
    "\n",
    "b = torch.zeros(10, 10, 2, 2)\n",
    "b[6][3] = 1\n",
    "b[4][4] = 1\n",
    "\n",
    "c = torch.zeros(10, 10, 2, 2)\n",
    "\n",
    "# loss_fn(b, a) < loss_fn(a, b)\n",
    "\n",
    "loss_fn(c, a), loss_fn(c, b), loss_fn(a, b), loss_fn(a, c), loss_fn(b, c), loss_fn(b, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[6][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cuda_devices = '4, 5'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cuda_devices\n",
    "\n",
    "ds_path = '/home/kudrjavtseviv/data/dataset_1'\n",
    "# ds_path = '/Users/vankudr/Documents/НИР-data/dataset_1'\n",
    "model_data_path = '/home/kudrjavtseviv/DL-framework/.data'\n",
    "\n",
    "checkpoints_path = os.path.join(model_data_path, 'checkpoints')\n",
    "logs_path = os.path.join(model_data_path, 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_m import HwrOnPrintedDataModule\n",
    "\n",
    "# DATA MODULE\n",
    "dm = HwrOnPrintedDataModule(\n",
    "    path={\n",
    "        'train': os.path.join(ds_path, 'train/result'),\n",
    "        'val': os.path.join(ds_path, 'val/result'),\n",
    "        'test': os.path.join(ds_path, 'test/result')\n",
    "    },\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose([\n",
      "  Resize(always_apply=False, p=1, height=640, width=420, interpolation=1),\n",
      "  Rotate(always_apply=False, p=1.0, limit=(-35, 35), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box', crop_border=False),\n",
      "  HorizontalFlip(always_apply=False, p=0.2),\n",
      "  VerticalFlip(always_apply=False, p=0.2),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.0], std=[1.0], max_pixel_value=255.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n",
      "Compose([\n",
      "  Resize(always_apply=False, p=1, height=640, width=420, interpolation=1),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.0], std=[1.0], max_pixel_value=1.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n",
      "Compose([\n",
      "  Resize(always_apply=False, p=1, height=640, width=420, interpolation=1),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.0], std=[1.0], max_pixel_value=1.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"
     ]
    }
   ],
   "source": [
    "dm.setup(stage='')\n",
    "loader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.__iter__().__next__()[1][0][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pr (torch.Tensor): A list of predicted elements\n",
    "        gt (torch.Tensor):  A list of elements that are to be predicted\n",
    "        eps (float): epsilon to avoid zero division\n",
    "        threshold: threshold for outputs binarization\n",
    "    Returns:\n",
    "        float: IoU (Jaccard) score\n",
    "    \"\"\"\n",
    "\n",
    "    if activation is None or activation == \"none\":\n",
    "        activation_fn = lambda x: x\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_fn = torch.nn.Sigmoid()\n",
    "    elif activation == \"softmax2d\":\n",
    "        activation_fn = torch.nn.Softmax2d()\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"Activation implemented for sigmoid and softmax2d\"\n",
    "        )\n",
    "\n",
    "    pr = activation_fn(pr)\n",
    "\n",
    "    if threshold is not None:\n",
    "        pr = (pr > threshold).float()\n",
    "\n",
    "\n",
    "    tp = torch.sum(gt * pr)\n",
    "    fp = torch.sum(pr) - tp\n",
    "    fn = torch.sum(gt) - tp\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + eps) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + eps)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    __name__ = 'dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        return 1 - f_score(y_pr, y_gt, beta=1., \n",
    "                           eps=self.eps, threshold=None, \n",
    "                           activation=self.activation)\n",
    "\n",
    "\n",
    "class BCEDiceLoss(DiceLoss):\n",
    "    __name__ = 'bce_dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid', lambda_dice=1.0, lambda_bce=1.0):\n",
    "        super().__init__(eps, activation)\n",
    "        if activation == None:\n",
    "            self.bce = nn.BCELoss(reduction='mean')\n",
    "        else:\n",
    "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.lambda_dice=lambda_dice\n",
    "        self.lambda_bce=lambda_bce\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        dice = super().forward(y_pr, y_gt)\n",
    "        bce = self.bce(y_pr, y_gt)\n",
    "        return (self.lambda_dice*dice) + (self.lambda_bce* bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp_spawn')` or `Trainer(accelerator='ddp_spawn')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 39\u001b[0m\n\u001b[1;32m     33\u001b[0m load_images_to_tb \u001b[39m=\u001b[39m LoadImageToTensorBoard(\n\u001b[1;32m     34\u001b[0m     max_number\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     35\u001b[0m     pad\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     38\u001b[0m \u001b[39m# TRAINER\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(\n\u001b[1;32m     40\u001b[0m     gpus\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mdevice_count(),\n\u001b[1;32m     41\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[1;32m     42\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[1;32m     43\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback, save_images_callback, load_images_to_tb], \n\u001b[1;32m     44\u001b[0m     logger\u001b[39m=\u001b[39;49mtb_logger)\n\u001b[1;32m     45\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, dm)\n",
      "File \u001b[0;32m~/DL-framework/.venv-hwr-train-2/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py:339\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    338\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/DL-framework/.venv-hwr-train-2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:486\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 486\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    487\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    488\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    489\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    490\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    491\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    492\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    493\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    494\u001b[0m     gpu_ids\u001b[39m=\u001b[39;49mgpu_ids,\n\u001b[1;32m    495\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    496\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    497\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    498\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    499\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    500\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    501\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    502\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    503\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    504\u001b[0m )\n\u001b[1;32m    505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m, log_gpu_memory)\n\u001b[1;32m    506\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/DL-framework/.venv-hwr-train-2/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:210\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, num_processes, tpu_cores, ipus, gpus, gpu_ids)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    209\u001b[0m \u001b[39m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init_strategy()\n",
      "File \u001b[0;32m~/DL-framework/.venv-hwr-train-2/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:760\u001b[0m, in \u001b[0;36mAcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_INTERACTIVE\n\u001b[1;32m    759\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 760\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    761\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer(strategy=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    762\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer(accelerator=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` is not compatible with an interactive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Trainer(strategy=None|\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(_StrategyType\u001b[39m.\u001b[39minteractive_compatible_types())\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m creation inside the worker function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    769\u001b[0m \u001b[39m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[39m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, TPUAccelerator) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    772\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, (SingleTPUStrategy, TPUSpawnStrategy)\n\u001b[1;32m    773\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp_spawn')` or `Trainer(accelerator='ddp_spawn')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from callbacks import SaveImagesCallback, LoadImageToTensorBoard\n",
    "\n",
    "# MODEL\n",
    "model = Unet(\n",
    "    features=[64, 128, 256])\n",
    "model.configure_optimizers(lr=1e3)\n",
    "\n",
    "# DATA MODULE\n",
    "dm = HwrOnPrintedDataModule(\n",
    "    path={\n",
    "        'train': os.path.join(ds_path, 'train/result'),\n",
    "        'val': os.path.join(ds_path, 'val/result'),\n",
    "        'test': os.path.join(ds_path, 'test/result')\n",
    "    },\n",
    "    batch_size=128,\n",
    "    num_workers=10,\n",
    "    pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "# UTILS\n",
    "tb_logger = pl.loggers.TensorBoardLogger(save_dir=logs_path)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='loss/val',\n",
    "    dirpath=checkpoints_path, #os.path.join(tb_logger.log_dir, 'checkpoints'), #'checkpoints',\n",
    "    filename='unet-epoch{epoch:02d}-val_loss{loss/val:.2f}',\n",
    "    auto_insert_metric_name=False,\n",
    "    save_top_k=10\n",
    ")\n",
    "save_images_callback = SaveImagesCallback(\n",
    "    image_dir=os.path.join(tb_logger.log_dir, 'images'),\n",
    "    max_number=3,\n",
    "    pad=(0, 2)\n",
    ")\n",
    "load_images_to_tb = LoadImageToTensorBoard(\n",
    "    max_number=3,\n",
    "    pad=(0, 2)\n",
    "    )\n",
    "\n",
    "# TRAINER\n",
    "trainer = pl.Trainer(\n",
    "    gpus=torch.cuda.device_count(),\n",
    "    max_epochs=5, \n",
    "    log_every_n_steps=2, \n",
    "    callbacks=[checkpoint_callback, save_images_callback, load_images_to_tb], \n",
    "    logger=tb_logger)\n",
    "trainer.fit(model, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
