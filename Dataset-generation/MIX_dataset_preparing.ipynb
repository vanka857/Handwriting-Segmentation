{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generators import BoxDatasetGenerator, ImageDataset, MixDatasetGenerator, MyAugmenter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import os\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/vankudr/Documents/НИР-data/dataset_1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING BOX DATASET FROM HANDWRITTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import default_generator, randperm\n",
    "from torch._utils import _accumulate\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "def random_split(dataset, lengths,\n",
    "                 generator=default_generator):\n",
    "    r\"\"\"\n",
    "    Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
    "\n",
    "    If a list of fractions that sum up to 1 is given,\n",
    "    the lengths will be computed automatically as\n",
    "    floor(frac * len(dataset)) for each fraction provided.\n",
    "\n",
    "    After computing the lengths, if there are any remainders, 1 count will be\n",
    "    distributed in round-robin fashion to the lengths\n",
    "    until there are no remainders left.\n",
    "\n",
    "    Optionally fix the generator for reproducible results, e.g.:\n",
    "\n",
    "    >>> random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))\n",
    "    >>> random_split(range(30), [0.3, 0.3, 0.4], generator=torch.Generator(\n",
    "    ...   ).manual_seed(42))\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Dataset to be split\n",
    "        lengths (sequence): lengths or fractions of splits to be produced\n",
    "        generator (Generator): Generator used for the random permutation.\n",
    "    \"\"\"\n",
    "    if math.isclose(sum(lengths), 1) and sum(lengths) <= 1:\n",
    "        subset_lengths: List[int] = []\n",
    "        for i, frac in enumerate(lengths):\n",
    "            if frac < 0 or frac > 1:\n",
    "                raise ValueError(f\"Fraction at index {i} is not between 0 and 1\")\n",
    "            n_items_in_split = int(\n",
    "                math.floor(len(dataset) * frac)  # type: ignore[arg-type]\n",
    "            )\n",
    "            subset_lengths.append(n_items_in_split)\n",
    "        remainder = len(dataset) - sum(subset_lengths)  # type: ignore[arg-type]\n",
    "        # add 1 to all the lengths in round-robin fashion until the remainder is 0\n",
    "        for i in range(remainder):\n",
    "            idx_to_add_at = i % len(subset_lengths)\n",
    "            subset_lengths[idx_to_add_at] += 1\n",
    "        lengths = subset_lengths\n",
    "        for i, length in enumerate(lengths):\n",
    "            if length == 0:\n",
    "                warnings.warn(f\"Length of split at index {i} is 0. \"\n",
    "                              f\"This might result in an empty dataset.\")\n",
    "\n",
    "    # Cannot verify that dataset is Sized\n",
    "    if sum(lengths) != len(dataset):    # type: ignore[arg-type]\n",
    "        raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")\n",
    "\n",
    "    indices = randperm(sum(lengths), generator=generator).tolist()  # type: ignore[call-overload]\n",
    "    return [Subset(dataset, indices[offset - length : offset]) for offset, length in zip(_accumulate(lengths), lengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwr_path = os.path.join(path, 'input/hwr/')\n",
    "boxes_train_path = os.path.join(path, 'train/boxes/')\n",
    "boxes_test_path = os.path.join(path, 'test/boxes/')\n",
    "boxes_val_path = os.path.join(path, 'val/boxes/')\n",
    "\n",
    "def pad(img, padding):\n",
    "    h, w, _ = img.shape\n",
    "    b_p, d_p, l_p, r_p = padding\n",
    "    return img[int(b_p * h): int((1 - d_p) * h), int(l_p * w): int((1 - r_p) * w)]\n",
    "\n",
    "hwr_transformer = lambda img: pad(img=img, padding=[0.23, 0.25, 0.01, 0.01])\n",
    "hwr_dataset = ImageDataset(path=hwr_path, transform=hwr_transformer)\n",
    "hwr_train, hwr_test, hwr_val = random_split(hwr_dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "def create_box_dataset(hwr_dataset, boxes_path, label):\n",
    "    print(f'Creating {label} boxes dataset')\n",
    "\n",
    "    hwr_dataloader = DataLoader(hwr_dataset, batch_size=1, shuffle=True)\n",
    "    box_gen = BoxDatasetGenerator(hwr_dataloader=hwr_dataloader,\n",
    "                                boxes_path=boxes_path,\n",
    "                                hwr_threshold=160)\n",
    "    box_gen.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train boxes dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Handwritten image processed: 100%|██████████| 1078/1078 [03:39<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test boxes dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Handwritten image processed: 100%|██████████| 308/308 [00:49<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating val boxes dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Handwritten image processed: 100%|██████████| 153/153 [00:24<00:00,  6.25it/s]\n"
     ]
    }
   ],
   "source": [
    "create_box_dataset(hwr_train, boxes_train_path, 'train')\n",
    "create_box_dataset(hwr_test, boxes_test_path, 'test')\n",
    "create_box_dataset(hwr_val, boxes_val_path, 'val')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING MIX DATASET FROM BOXES AND PRINTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mix_dataset(printed_dataset, boxes_dataset, result_path, boxes_per_printed=250):\n",
    "    n1 = boxes_per_printed * len(printed_dataset)\n",
    "    n2 = len(boxes_dataset)\n",
    "    if n1 > n2:\n",
    "        raise ValueError(f'{n1} > {n2}')\n",
    "\n",
    "    printed_dataloader = DataLoader(printed_dataset, batch_size=1, shuffle=False)\n",
    "    boxes_dataloader = DataLoader(boxes_dataset, batch_size=1, shuffle=True)\n",
    "    boxes_aug = MyAugmenter(random_scaling=[0.15, 0.25], random_rotation=[-5, 5])\n",
    "    mix_gen = MixDatasetGenerator(printed_dataloader=printed_dataloader,\n",
    "                                printed_replica_factor=1,\n",
    "                                boxes_dataloader=boxes_dataloader,\n",
    "                                boxes_per_printed=boxes_per_printed,\n",
    "                                result_path=result_path,\n",
    "                                printed_threshold=100,\n",
    "                                hwr_threshold=160,\n",
    "                                boxes_augmenter=boxes_aug)\n",
    "\n",
    "    mix_gen.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printed_path = os.path.join(path, 'input/printed/')\n",
    "printed_path = '/Users/vankudr/Documents/НИР-data/other/PubLayNet10k'\n",
    "printed_dataset = ImageDataset(path=printed_path)\n",
    "printed_train, printed_test, printed_val = random_split(printed_dataset, [0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boxes read: 100%|██████████| 33181/33181 [01:19<00:00, 415.86it/s]\n"
     ]
    }
   ],
   "source": [
    "boxes_train_path = os.path.join(path, 'train/boxes/')\n",
    "boxes_train = ImageDataset(path=boxes_train_path, read_in_memory=True, multiplication_factor=100)\n",
    "result_train_path = os.path.join(path, 'train/result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Printed images batch processed: 100%|██████████| 7057/7057 [11:49<00:00,  9.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "# create_mix_dataset(printed_train, boxes_train, result_train_path)\n",
    "cProfile.run('create_mix_dataset(printed_train, boxes_train, result_train_path)', 'results_train.prof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boxes read: 100%|██████████| 9296/9296 [00:31<00:00, 295.13it/s]\n"
     ]
    }
   ],
   "source": [
    "boxes_test_path = os.path.join(path, 'test/boxes/')\n",
    "boxes_test = ImageDataset(path=boxes_test_path, read_in_memory=True, multiplication_factor=100)\n",
    "result_test_path = os.path.join(path, 'test/result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Printed images batch processed: 100%|██████████| 2016/2016 [03:26<00:00,  9.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "# create_mix_dataset(printed_train, boxes_train, result_train_path)\n",
    "cProfile.run('create_mix_dataset(printed_test, boxes_test, result_test_path)', 'results_test.prof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boxes read: 100%|██████████| 4587/4587 [00:17<00:00, 258.72it/s]\n"
     ]
    }
   ],
   "source": [
    "boxes_val_path = os.path.join(path, 'val/boxes/')\n",
    "boxes_val = ImageDataset(path=boxes_val_path, read_in_memory=True, multiplication_factor=100)\n",
    "result_val_path = os.path.join(path, 'val/result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Printed images batch processed: 100%|██████████| 1008/1008 [01:42<00:00,  9.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "# create_mix_dataset(printed_train, boxes_train, result_train_path)\n",
    "cProfile.run('create_mix_dataset(printed_val, boxes_val, result_val_path)', 'results_val.prof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 30 15:28:45 2023    results_train.prof\n",
      "\n",
      "         131288736 function calls (129489104 primitive calls) in 710.137 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 264 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1771307   93.904    0.000   93.904    0.000 {built-in method torch.stack}\n",
      "    14114   91.796    0.007   91.796    0.007 {imwrite}\n",
      "     7057   87.688    0.012   87.688    0.012 {imread}\n",
      "     7057   53.785    0.008  514.567    0.073 /Users/vankudr/Yandex.Disk.localized/MIPT/НИР/Handwriting-Segmentation/Dataset-generation/src/generators/hwr_generator.py:153(cover_printed_with_boxes)\n",
      "  1771307   37.638    0.000   37.638    0.000 {cvtColor}\n",
      "  1764250   37.270    0.000   37.270    0.000 {warpAffine}\n",
      "  1764250   32.177    0.000   32.177    0.000 {resize}\n",
      "  1764250   21.843    0.000   21.843    0.000 {dilate}\n",
      "3542614/1771307   19.583    0.000  130.886    0.000 /opt/anaconda3/envs/scidev/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:84(default_collate)\n",
      "  1771308   16.830    0.000   16.830    0.000 {built-in method torch._ops.profiler._record_function_enter}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7fc190ad6d60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats\n",
    "\n",
    "# загружаем результаты профилирования в pstats\n",
    "stats = pstats.Stats('results_train.prof')\n",
    "\n",
    "# сортируем по времени выполнения и выводим топ-10 функций\n",
    "stats.sort_stats('tottime').print_stats(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scidev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
